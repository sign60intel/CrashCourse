# # c39eab0e6d4c9845d70cbc0322825e79d7361436
#+REVEAL_ROOT: https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.7.0
#+OPTIONS: reveal_center:t reveal_progress:t reveal_history:t reveal_control:t
#+OPTIONS: reveal_mathjax:t reveal_rolling_links:t reveal_keyboard:t
#+OPTIONS: reveal_overview:t num:nil reveal_toc:nil
#+OPTIONS: reveal_width:1200 reveal_height:800
#+REVEAL_MARGIN: 0.2
#+REVEAL_MIN_SCALE: 0.5
#+REVEAL_MAX_SCALE: 2.5
#+REVEAL_TRANS: none
#+REVEAL_THEME: sky
#+OPTIONS: text
#+OPTIONS: toc:nil num:nil
#+REVEAL_HLEVEL: 1
# #+REVEAL_HLEVEL: 999
#+REVEAL_EXTRA_CSS: ./presentation.css
#+REVEAL_PLUGINS: (highlight)
#+STARTUP: latexpreview
#+MACRO: color @@html:<font color="$1">$2</font>@@

#+TITLE: Virtual Memory
#+AUTHOR: Sergey V. Ignatov
#+EMAIL: s.ignatov@samsung.com
# #+DATE: 18-09-2018

* *_Agenda_*
  - *Virtual Memory*
  - *Memory Layout of Process*
  - *Virtual Method Table*
* *_Virtual Memory_*
  - Basic memory management
  - Swapping
  - Virtual Memory
  - Page replacement algorithms
  - Modeling page replacement algorithms
  - Design issues for paging systems
  - Implementation issues
  - Segmentation

** *_History_*
   - *Virtual Memory* was developed in approximately 1959 - 1962, at the University of Manchester for the Atlas Computer, completed in 1962.
   - in 1961, Burroughs released the B5000, the first commercial computer with *Virtual Memory*.

** *_Virtual Memory Terminology_*
    - *Virtual Memory*: A storage allocation scheme in which secondary memory can be addressed as though it were part of main memory. The addresses a program may use to reference memory are distinguished from the addresses the memory system uses to identify physical storage sites, and program-generated addresses are translated automatically to the corresponding machine addresses.
    - *Virtual Address*: The address assigned to a location in *Virtual Memory* to allow that location to be accessed as though it were part of main memory.
    - *Virtual Address Space*: The virtual storage assigned to a process.
    - *Address Space*: The range of memory addresses avaliable to a process
    - *Real (Physical) Address*: The address of a storage location in main memory
    - *Page*: is a contiguous block of virtual addresses
    - *Frame*: is a contiguous block of physical addresses

** *_Memory Management_*
   - Fundamental characteristics to memory management:
     - All memory references are logical addresses that are dynamically translated into physical addresses at run time
     - A process may be broken up into a number of pieces that don't need to be contiguously located in main memory during execution
   - If these two characteristics are present, it is not necessary that all of the pages of segments of a process be in main memory during execution

** *_Memory Management_*
   - *Goals*:
     - Provide a convenient programming model
     - Efficiently allocate a scarce resource
     - Protect programs from each other
     - Protect the OS from programs
   - *Mechanisms*:
     - Physical and virtual addressing
     - Paging and segmentation
     - Page table management
   - *Policies*:
     - Page replacement algorithms

** *_Virtual Memory_*
   - {{{color(blue, Virtual Memory)}}} - separation of user logical memory from physical memory
     - Only part of the program needs to be in memory for execution
     - Logical address space can therefore be much larger than physical address space
     - Allows address spaces to be shared by several processes
     - Allows for more efficient process creation
     - Programs use virtual addresses rather than real addresses to store instructions and data
     - When the program is actually executed, the virtual addresses are converted into real memory addresses
   - {{{color(blue, Virtual Memory)}}} can be implemented via:
     - Demand paging
     - Demand segmentation

** *_Mapping Virtual to Physical Addresses_*
   - OS must provide a mapping virtual addresses to physical addresses:
     - The same virtual addresses in two different processes does not map to the same phusical address
     - Some virtual addresses do not map to any physical address

** *_Virtual Memory Implementation_*
#+ATTR_HTML: :width 800px
[[./images/VirtualMemoryScheme.jpg]]

** *_Virtual Memory Implementation_*
   - To facilitate copying virtual memory into physical memory, the Operating System divides virtual memory into pages, each of which contains a fixed number of addresses.
   - Each page is stored on a disk until it is needed.
   - When the page is needed, the Operating System copies it from disk to main memory, translating the virtual addresses into physical addresses

** *_Process Virtual Address Space_*
#+ATTR_HTML: :width 340px
[[./images/ProcessVirtualSpace.png]]

** *_Process Address With Shared Library_*
#+ATTR_HTML: :width 1000px
[[./images/WithSharedLibraries.png]]

** *_Computer System Memory Hierarchy_*
#+ATTR_HTML: :width 1000px
[[./images/memory-hierarchy.jpg]]
** *_Computer System Memory Hierarchy_*
   - *Levels* of Memory Hierarchy
     - Cache: small amount of fast, expensive memory
       - L1 (Level 1) cache: usually on the CPU chip
       - L2 & L3 cache: off-chip, made of SRAM (Static Random Access Memory)
     - Main Memory: medium-speed, medium price memory (DRAM Dynamic Random Access Memory)
     - Disk: many amount of slow, cheap, non-volatile storage
   - Memory manager handles the memory hierarchy

** *_Where Do Addresses Come From?_*
   - *Compile Time*: The compiler generates the exact physical location in memory starting from some fixed starting position. The OS does nothing.
   - *Load Time*: Compiler generates an address, but at load time the OS determines the process' starting position. Once the process loads, it does not move in memory.
   - *Execution Time*: Compiler generates an address, and OS can move it around in memory as needed.

** *_Memory Management Unit (MMU)_*
   - MMU is the hardware base that makes a virtual memory system possible.
   - MMU allows software to reference physical memory by virtual addresses, quite often more than one.
   - MMU accomplishes this through the use of page and page tables.
   - MMU uses a section of memory to translate virtual addresses into physical addresses via a series of table lookups.
   - The software that handles the page fault is generally part of an operating system and the hardware that detects this situation.

** *_Page Faults_*
   - *Page Fault* is an interrupt to the software raised by the hardware
     - when a program accesses a page that is not mapped in physical memory.
     - when a program accesses a memory location in its memory and the page corresponding to that memory is not loaded.
     - when a program accesses a memory location in its memory and the program does not have privileges to access the page corresponding to that memory.
   - When a page being referred to by the virtual address is not loaded as a page frame in to the memory, a page fault is occured which causes the CPU to trap the Operating System.
   - The Operating System removes a page frame from the memory and loads the new page in to the freed location at the same time making appropriate changes to the page table.
   - There are a page replacement algorithms available as *The Optimal Page Replacement*, *The Not Recently Used Page Replacement*, *FIFO* etc.

** *_Segmentation_*
   - *Segmentation* involves the relocation of variable sized segments sized segments into the physical address space.
   - Generally these segments are continuous units, and are referred to in programms by their segment number and an offset to the requested data.
   - Efficient *segmentation* relies on programs that are very thoughtfully written for their target system.
   - Since *segmentation* relies on memory that is located in single large blocks, it is very possible that enough free space is available to load a new module, but can not be utilized.
   - *Segmentation* may also suffer from internal fragmentation if segments are not variable-sized, where memory above the segment is not used by the program but is still "reserved" for it.

** *_Paging_*
   - *Paging* provides a somewhat easier interface for programs, in that its operation tends to be more automatic and thus transparent.
   - Each unit of transfer, referred to as a page, is of a fixed size and swapped by the virtual memory manager outside of the program's control.
   - Instead of utilizing a segment/offset addressing approach, as seen in *segmentation*, *paging* uses a linear sequence of virtual addresses which are mapped to physical memory as necessary.
   - Due to this addressing approach, a single program may refer to series of many non-continuous segments.
   - Although some internal fragmentation may still exist due to the fixed size of the pages, the approach virtually eliminates external fragmentation.

** *_Paging_*
   - A technique used virtual memory operating systems to help ensure that the data you need is available as quickly as possible.
   - The operating system copies a certain number of pages from your storage device to main memory.
   - When a program needs a page that is not in main memory, the operating system copies the required page into memory and copies another page back to the disk.

** *_Paging Replacement Algorithms_*
   - *OPT(MIN)*: eliminate the page that be not expected to be used.
   - *FIFO(First Input / First Output)*: rather than choosing the victim page at random, the oldest page is the first to be removed.
   - *LRU(Least Recently Used)*: move out the page that is the least rarely used.
   - *LFU(Least Frequently Used)*: move out the page that is not used often in the past.

** *_Summary_*
   - *Virtual Memory* is a common part of most operating systems on computers.
   - It has become so common because it provides a big benefit for users at a very low cost.
   - Benefits of executing a program that is only partially in memory.
   - Program is _no longer constrained_ by the amount of physical memory
     - user would be able to write programs for an extremely large virtual address space.
   - _more programs_ could be run at the same time
     - increase CPU utilization and throughput.
   - _less I/O_ would be needed _to load or swap_ each user program
     - run faster.
* *_Memory Layout of Process_*
  - A typical memory representation of a computer program consists of following sections:
    - *Text Segment*
    - *Initialized Data Segment (Data*)
    - *Uninitialized Data Segment (BSS)*
    - *Memory Mapping Segment*
    - *Stack*
    - *Heap*
** *_Memory Layout of Process_*
 #+ATTR_HTML: :width 1200px
[[./images/StandardMemoryLayout.jpg]]
** *_Memory Layout of Process_*
   - Each distinct type of content typically occupies one or several continuous blocks of memory within the virtual address space. The initial placement of these blocks is managed by the loader of the operating system, the content of these blocks is managed by the process owning them.
   - Layout of the blocks that contain executable code and static data is determined by the compiler and does not change during process execution. The blocks that contain stack and heap change during process execution.
   - The blocks containing the heap and the stack may need to grow as the process owning them executes. The need for growth is difficult to predict during the initial placement of the blocks. To avoid restricting the growth by placing either heap or stack too close to other blocks, they are typically placed near the opposite ends of the process virtual address space with an empty space between them. The heap block is then grown upwards and the stack block downwards as necessary.
** *_Text Segment_*
   - A *Text Segment* (*Code Segment*) is one of the sections of a program in an object file or in memory, which contains *executable instructions*.
   - As a memory region, a *text segment* may be placed below the *heap* or *stack* in order to prevent heaps and stack overflows from overwriting it.
   - Usually, the *text segment* is sharable so that only a *single copy* needs to be in memory for frequently executed programs, such as text editors, the C compiler, the shells, and so on. Also, the *text segment* is often *read-only*, to prevent a program from accidentally modifying its instructions
** *_Initialized Data Segment (Data)_*
   - *Initialized Data Segment*, usually called simply the *Data Segment*. A *Data Segment* is a portion of virtual address space of a program, which contains the *global variables* and *static variables* that are *initialized* by the programmer.
   - *Data Segment* is *not read-only*, since the values of the variables can be altered at run time.
   - This segment can be further classified into *initialized read-only* area and *initialized read-write* area.
   - Examples: ~static int i = 10;~ will be stored in data segment and global ~int i = 10;~ will also be stored in *Data Segment*.
** *_Uninitialized Data Segment (BSS)_*
   - *Uninitialized Data Segment*, often called the *"bss"* segment, named after an ancient assembler operator that stood for *"block started by symbol"*. Data in this segment is initialized by the kernel to arithmetic 0 before the program starts executing
   - *Uninitialized Data* starts at the end of the data segment and contains all global variables and static variables that are initialized to zero or do not have explicit initialization in source code.
   - The *BSS Segment* is *read-write* area.
   - Examples: a variable declared as ~static int i;~ and a global variable declared as ~int j;~ would be contained in the *BSS Segment*.
** *_Memory Mapping Segment_*
   - In the middle of the process's address space, a large region is reserved for *shared objects*. *Shared libraries* are located at the top of the address space and grow downwards.
   - When a new process is created, the process manager first maps the two segments from the executable into memory. It then decodes the program's header. If the program header indicates that the executable was linked against a *shared library*, the process manager will extract the name of the dynamic interpreter from the program header. The dynamic interpreter points to a *shared library* that contains the runtime linker code. The process manager will load this shared library in memory and will then pass control to the runtime linker code in this library.
** *_Stack_*
   - The *Stack* area contains the *program stack*, i.e., a *LIFO* structure typically located in the higher memory addresses right below the *OS kernel space*. Usually it grows *downwards to lower addresses*.
   - This area is devoted to store all the data needed by a function call in a program. Specifically, the set of values pushed for one function call is named a *stack frame*, and consists of all the automatic variables (i.e., local to the scope of the function’s body and including any actual parameters passed as input to the function) and the caller’s return address. This is exactly how recursive functions are implemented in C: each time a recursive function calls itself, a new stack frame is allocated on top of the stack, thus the set of variables within one call are completely independent from those of another function call.
   - A *stack pointer register* tracks the *top of the stack* (i.e., how much of the stack area the process is currently using), and it is adjusted each time a value is “pushed” onto the *stack*. If the *stack pointer* meets the heap pointer (or if it eventually reaches the limit posed by ~RLIMIT_STACK~), the available free memory is exhausted.
** *_Stack Frame_*
#+ATTR_HTML: :width 600px
[[./images/StackFrame.png]]
** *_Heap_*
   - *Heap* is the segment where dynamic memory allocation usually takes place, i.e., to allocate memory requested by the programmer for variables whose size can be only known at run-time and cannot be statically determined by the compiler before program execution. The *heap* area begins at the end of the *BSS segment* and grows *upwards* to higher memory addresses. It is managed by ~malloc/new~, ~free/delete~, which may use the ~brk~ and ~sbrk~ system calls to adjust its size.
   - This area is shared by all shared libraries and dynamically loaded modules in a process.
** *_Producing an Object Module_*
   - Assembler (or compiler) translates program into machine instructions
   - Provides information for building a complete program from the pieces
     - *Header*: described contents of object module
     - *Text segment*: translated instructions
     - *Static date segment*: data allocate for the life of the program
     - *Relocation info*: for contents the depend on absolute location of loaded program
     - *Symbol table*: global definitions and external references
     - *Debug info*: for associating with source code
** *_Linking Object Modules_*
   - Produces an executable image
     - Merges segments
     - Resolve labels (determine their addresses)
     - Patch location-dependent and external references
   - Could leave location dependencies for fixing by a relocating loader
     - But with virtual memory, no need to do this
     - Program can be loaded into absolute location in virtual memory space
** *_Loading a Program_*
   - Load from image file on disk into memory
     - Read header to determine segment sizes
     - Create virtual address space
     - Copy text and initialized data into memory
     - Set up arguments on stack
     - Initialize registers (including *stack pointer*, *frame pointer*)
     - Jump to startup routine
       - Copies arguments and calls ~main~
       - When ~main~ returns, do ~exit~ syscall
** *_Dynamic Linking_*
   - Only link/load library procedure when it is called
     - Requires procedure code to be relocatable
     - Avoids image bloat caused by static linking of all (transitively) referenced libraries
     - Automatically picks up new library versions
   - Lazy Linkage
     - Linkage performed only when function called
     - Only functions actually used are linked
* *_Virtual Method Table_*
  - A *virtual method table* (VMT), *virtual function table*, *virtual call table*, *dispatch table*, *vtable*, or *vftable* is a mechanism used in a programming language to support dynamic dispatch (or run-time method binding).
  - The *virual table* is a lookup table of functions, used to resolve function calls in a dynamic/late binding manner.
** *_Polymorphism_*
   - A Greek term which means "many forms"
   - *Polymorphism* is classified into 2 branches
     - Compile Time Polymorphism / {{{color(red, Early Binding)}}} / Static Binding
     - Runtime Polymorphism / {{{color(red, Late Binding)}}} / Dynamic Binding
** *_Binding_*
   - For every function call; compiler binds or links the call to one function definition.
   - This linking can happen at 2 different time
     - At the time of compiling program
     - At runtime
** *_Compile Time Polymorphism_*
   - *Function Overloading* it an example of *Compile Time Polymorphism*
   - The decision of binding among several functions is taken by considering formal arguments of the functions, their data type and their sequence.
** *_Example of Compile Time Polymorphism_*
#+BEGIN_SRC c++
void MyFunction(int i)
{
  cout << "an int is passed" << endl;
}
void MyFunction(char c)
{
  cout << "a char is passed" << endl;
}

int main()
{
  MyFunction(10);
  MyFunction('x');
  return 0;
}
#+END_SRC
#+BEGIN_SRC c++
an int is passed
a char is passed
#+END_SRC
** *_Runtime Polymorphism_*
   - In *late binding*; call to a function is resolved at *Runtime*, the compiler determines the type fo object at *execution time* and then binds the function call to a function definition.
   - *Late Binding* is also called as *Dynamic Binding* or *Runtime Binding*.
   - *Virtual Functions* are example of *Late Binding* in C++
   - *Runtime polymorphism* is achieved using pointers.
     - a base class pointer variable can hold address of derived class object, but it can access only members of base class.
** *_Example of Runtime Polymorphism_*
#+BEGIN_SRC c++
class base
{
public:
  void show() {
    cout << "Show from base" << endl;
  }
};
class derived : public base
{
public:
  void show() {
    cout << "Show from derived" << endl;
  }
};

int main()
{
  base *ptr;
  derived obj;

  ptr = &obj;
  ptr->show();
  return 0;
}
#+END_SRC
#+BEGIN_SRC c++
Show from base
#+END_SRC
** *_Using ~virtual~ Keyword_*
#+BEGIN_SRC c++
class base
{
public:
  virtual void show() {
    cout << "Show from base" << endl;
  }
};
class derived : public base
{
public:
  void show() {
    cout << "Show from derived" << endl;
  }
};

int main()
{
  base *ptr;
  derived obj;

  ptr = &obj;
  ptr->show();
  return 0;
}
#+END_SRC
#+BEGIN_SRC c++
Show from derived
#+END_SRC


** *_Using ~virtual~ Keyword_*
   - With *virtual* keyword *late binding* takes and derived version of the function will be called, because base ponter points to an derived type of object.
   - {{{color(red, In runtime polymorphism the call to a function is resolved at runtime depending upon the type of object.)}}}
** *_Virtual Functions_*
   - A virtual function is a member function that is declared as ~virtual~ within a base class and redefined by a derived class.
   - To create *virtual function*, precede the base version of function's declaration with the keyword ~virtual~.
   - When a class containing *virtual function* is inherited, the {{{color(blue, derived class can redefine-override the virtual function to suit its own unique needs.)}}}
   - The method name and type signature should be same for both base and derived version of function.
** *_Overriding vs Overloading_*
   - *Overloading* requires *unique signatures* whereas *overriding* requires *the same signature and return type*.
   - *Overloading* requires that each *overloaded* version of the function be specified within the same scope whereas *overriding* requires each *overriden* version be specified within the scompe of each derived class.
   - Call to an *Overloaded* method is resolved at *compile time*, while call to an *Overriden* method is resolved at runtime depending upon the type of object.
** *_Late Resolving in Compilers_*
   - Compiler maintains two things for *Late Resolving*:
     - {{{color(red,vtable)}}}: a table of function pointers. It is maintained per class. So when the compiler encounters a class definition that contains a *virtual* method, it builds a ~vtable~ for that class. The ~vtable~ contains the addresses of all of the *virtual* methods for the class.
     - All objects of the same class will share the same ~vtable~
     - When the compiler encounters a derived class definition that inherits from this base class, it *makes a copy* of the ~vtable~ from the base class for the derived class.
     - Now, for any method in the derived class that *over-rides* a virtual method in the base class, the compiler sets the address for that method to the derived class method's address.
     - All the virtual function tables are in the *read-only memory* associated with your process, which protects them from unintentional overwrites.
     - The function themselves (their assembly instructions) are stored in the ~.text~ section.
     - {{{color(green,vptr)}}}: a pointer to ~vtable~. It is maintained per object (see {{{color(green,this)}}} fo an example). When the object of the derivdd class is created a pointer to the class's ~vtable~ is added to the object.
** *_Example for Late Binding_*
#+BEGIN_SRC c++
class Employee
{
public:
	virtual void raiseSalary()
	{ /* common raise salary code */ }

	virtual void promote()
	{ /* common promote code */ }
};

class Manager: public Employee {
	virtual void raiseSalary()
	{ /* Manager specific raise salary code, may contain
		increment of manager specific incentives*/ }

	virtual void promote()
	{ /* Manager specific promote */ }
};

// Similarly, there may be other types of employees

// We need a very simple function to increment salary of all employees
// Note that emp[] is an array of pointers and actual pointed objects can
// be any type of employees. This function should ideally be in a class
// like Organization, we have made it global to keep things simple
void globalRaiseSalary(Employee *emp[], int n)
{
	for (int i = 0; i < n; i++)
		emp[i]->raiseSalary(); // Polymorphic Call: Calls raiseSalary()
							// according to the actual object, not
							// according to the type of pointer
}
#+END_SRC
** *_Late Resolving in Compilers_*
   - Compilers adds additional code at two places to maintain and use ~vptr~:
     + Code in every constructor. This code sets ~vptr~ of the object being created. This code sets ~vptr~ to point to ~vtable~ of the class.
     + Code with polymorphic function call. Wherever a polymorphic call is made, compiler inserts a code to first look for ~vptr~ using base class pointer or reference (In the above example, since pointed or referred object is of derived type, ~vptr~ of derived class is accessed). Once ~vptr~ is fetched, ~vtable~ of derived class can be accessed. Using ~vtable~, address of derived class function ~show()~ is accessed and called.
** *_Late Resolving in Compilers_*
#+ATTR_HTML: :width 1200px
[[./images/VirtualFunction.png]]
** *_Structure of Virtual Table_*
#+BEGIN_SRC c++
class Base {
    public:
        virtual ~Base() { }
        virtual void method() = 0;
};

class Derived: public Base{
    public:
        virtual ~Derived() {}
        void method() {}
};

int main() {
    Base* m = new Derived();
    delete m;
}
#+END_SRC
#+BEGIN_SRC c++
(gdb) info vtbl m
vtable for 'Base' @ 0x400af0 (subobject @ 0x603010):
[0]: 0x400986 [Derived::~Derived()]
[1]: 0x4009c0 [Derived::~Derived()]
[2]: 0x4009e6 [Derived::method()]
#+END_SRC
** *_Location in Memory_*
#+BEGIN_SRC c++
readelf --sections a.out
There are 36 section headers, starting at offset 0x6420:

Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
  [ 0]                   NULL             0000000000000000  00000000
       0000000000000000  0000000000000000           0     0     0
  [13] .text             PROGBITS         00000000004007a0  000007a0
       0000000000000302  0000000000000000  AX       0     0     16
  [14] .fini             PROGBITS         0000000000400aa4  00000aa4
       0000000000000009  0000000000000000  AX       0     0     4
  [15] .rodata           PROGBITS         0000000000400ac0  00000ac0
       00000000000000d0  0000000000000000   A       0     0     32
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings), l (large)
  I (info), L (link order), G (group), T (TLS), E (exclude), x (unknown)
  O (extra OS processing required) o (OS specific), p (processor specific)
#+END_SRC
   - ~[0x04007a0-0x0400aa4]~ – is the text section containing disassembly of functions (0x400986)
   - ~[0x0400ac0-0x0400b90]~ – is the read only section containing the vtables (0x400af0)
** *_Read Only Memory_*
#+BEGIN_SRC c++
objdump -s -j .rodata ./a.out

./a.out:     file format elf64-x86-64

Contents of section .rodata:
 400ac0 01000200 00000000 00000000 00000000  ................
 400ad0 00000000 00000000 00000000 00000000  ................
 400ae0 00000000 00000000 600b4000 00000000  ........`.@.....
 400af0 86094000 00000000 c0094000 00000000  ..@.......@.....
 400b00 e6094000 00000000 00000000 00000000  ..@.............
 400b10 00000000 00000000 00000000 00000000  ................
 400b20 00000000 00000000 800b4000 00000000  ..........@.....
 400b30 32094000 00000000 60094000 00000000  2.@.....`.@.....
 400b40 80074000 00000000 37446572 69766564  ..@.....7Derived
 400b50 00000000 00000000 00000000 00000000  ................
 400b60 f0206000 00000000 480b4000 00000000  . `.....H.@.....
 400b70 800b4000 00000000 34426173 65000000  ..@.....4Base...
 400b80 90206000 00000000 780b4000 00000000  . `.....x.@.....
#+END_SRC
   - When looking at the line 0x400af0 we notice that the values are not what we expect. The byte order is reversed in objdump compared to the disassembly. The raw bytes are ~[0x86, 0x9, 0x40, 0x0]~ with *big endian byte order* this results in 0x400986 and in *little endian byte order* this results in 0x860940.
#+BEGIN_SRC c++
(gdb) x/6x 0x400af0
0x400af0 [_ZTV7Derived+16]:     0x00400986      0x00000000      0x004009c0      0x00000000
0x400b00 [_ZTV7Derived+32]:     0x004009e6      0x00000000
#+END_SRC
